# -*- coding: utf-8 -*-
"""
Created on 2025/10/4

@author: Yifei Sun
"""
# -*- coding: utf-8 -*-
"""
Created on 2025/10/3

@author: Yifei Sun
"""
from collections import defaultdict
import re
import torch
import numpy as np
import pyrfm
from typing import Union, Tuple, List, Optional, Dict

from pathlib import Path
import matplotlib

# matplotlib.use("Agg")
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D  # noqa: F401
from matplotlib.colors import TwoSlopeNorm

import time

"""
Î”_ğ“¢ u_ğ“¢ âˆ’ (1/t) u_ğ“¢ = 0,  where  u_ğ“¢ = 1  on  C
X = âˆ’ ( âˆ‡_ğ“¢ u_ğ“¢ ) / || âˆ‡_ğ“¢ u_ğ“¢ ||
Î”_ğ“¢ Ï†_ğ“¢ = âˆ‡_ğ“¢ Â· X,  where  Ï†_ğ“¢ = 0 on C

where t is a small, positive constant and Ï† is the geodesic distance.

From the definition
    X = âˆ’ âˆ‡_ğ“¢ u / || âˆ‡_ğ“¢ u ||

we compute
    âˆ‡_ğ“¢ Â· X = âˆ’ âˆ‡_ğ“¢ Â· ( âˆ‡_ğ“¢ u / || âˆ‡_ğ“¢ u || )

Let g = || âˆ‡_ğ“¢ u ||. Then
    âˆ‡_ğ“¢ Â· X = âˆ’ [ âˆ‡_ğ“¢(1/g) Â· âˆ‡_ğ“¢ u  +  (1/g) Î”_ğ“¢ u ]

Since
    âˆ‡_ğ“¢ g = (1/g) ( âˆ‡_ğ“¢Â² u ) âˆ‡_ğ“¢ u
    âˆ‡_ğ“¢ (1/g) = âˆ’ (1/gÂ³) ( âˆ‡_ğ“¢Â² u ) âˆ‡_ğ“¢ u

we obtain
    âˆ‡_ğ“¢ Â· X = âˆ’ (1/||âˆ‡_ğ“¢ u||) Î”_ğ“¢ u
              + ( (âˆ‡_ğ“¢ u)áµ€ (âˆ‡_ğ“¢Â² u) (âˆ‡_ğ“¢ u) ) / ||âˆ‡_ğ“¢ u||Â³
"""


def func_u(p: torch.Tensor) -> torch.Tensor:
    """
    Example function u(x, y, z) = sin(x) * exp(cos(y - z))
    """
    return (torch.sin(p[:, 0]) * torch.exp(torch.cos(p[:, 1] - p[:, 2]))).unsqueeze(-1)


def func_rhs(p: torch.Tensor, normal: torch.Tensor, mean_curvature: torch.Tensor) -> torch.Tensor:
    """
    Laplaceâ€“Beltrami of u restricted to a surface embedded in R^d.
    Uses: Î”_S u = Î” u - n^T (Hess u) n - H * (âˆ‡u Â· n)

    Args:
        p: (N, d) surface points, requires grad.
        normal: (N, d) outward unit normals (will be normalized just in case).
        mean_curvature: (N,) or (N,1) mean curvature H = div(n) with your sign convention.

    Returns:
        (N, 1) tensor of Î”_S u at p.
    """
    if not p.requires_grad:
        p = p.detach().clone().requires_grad_(True)

    N, d = p.shape
    # u, âˆ‡u
    u = func_u(p).squeeze(-1)  # (N,)
    grad_u = torch.autograd.grad(u, p,
                                 grad_outputs=torch.ones_like(u),
                                 create_graph=True, retain_graph=True)[0]  # (N, d)

    # Hessian âˆ‡^2 u: stack âˆ‚(âˆ‚_i u)/âˆ‚x_j over i
    H_rows = []
    for i in range(d):
        gi = grad_u[:, i]  # (N,)
        Hi = torch.autograd.grad(gi, p,
                                 grad_outputs=torch.ones_like(gi),
                                 create_graph=True, retain_graph=True)[0]  # (N, d)
        H_rows.append(Hi.unsqueeze(1))  # (N, 1, d)
    H = torch.cat(H_rows, dim=1)  # (N, d, d)

    # Ambient Laplacian Î”u = trace(H)
    lap_u = H.diagonal(dim1=1, dim2=2).sum(dim=1, keepdim=True)  # (N,1)

    # Ensure unit normals
    n = normal / (normal.norm(dim=1, keepdim=True) + 1e-12)  # (N,d)

    # Second normal derivative n^T H n
    nHn = torch.einsum('bi,bij,bj->b', n, H, n).unsqueeze(-1)  # (N,1)

    # Normal derivative âˆ‚_n u
    dn_u = (grad_u * n).sum(dim=1, keepdim=True)  # (N,1)

    # Mean curvature shape (N,1)
    Hmean = mean_curvature.view(-1, 1)

    # Laplaceâ€“Beltrami
    lb = lap_u - nHn - 2 * Hmean * dn_u  # (N,1)
    return lb


def compute_grads_u(model, p, normal):
    # X = âˆ’(âˆ‡_S u) / âˆ¥âˆ‡_S u âˆ¥
    n = normal / (normal.norm(dim=1, keepdim=True) + 1e-12)  # (N,3)
    u = model(p).squeeze(-1)  # (N,)

    # æ¬§å¼æ¢¯åº¦
    ux = model.dForward(p, (1, 0, 0)).squeeze(-1)
    uy = model.dForward(p, (0, 1, 0)).squeeze(-1)
    uz = model.dForward(p, (0, 0, 1)).squeeze(-1)

    grad_u = torch.zeros(p.shape[0], 3, device=p.device, dtype=p.dtype)
    grad_u[:, 0] = ux
    grad_u[:, 1] = uy
    grad_u[:, 2] = uz

    # æŠ•å½±åˆ°åˆ‡ç©ºé—´ï¼šgrad_S u = (I - nn^T) grad_u
    grad_u_tan = grad_u - (grad_u * n).sum(dim=1, keepdim=True) * n

    return grad_u_tan


def compute_X(model, p, normal):
    # X = âˆ’(âˆ‡_S u) / âˆ¥âˆ‡_S u âˆ¥
    n = normal / (normal.norm(dim=1, keepdim=True) + 1e-12)  # (N,3)
    u = model(p).squeeze(-1)  # (N,)

    # æ¬§å¼æ¢¯åº¦
    ux = model.dForward(p, (1, 0, 0)).squeeze(-1)
    uy = model.dForward(p, (0, 1, 0)).squeeze(-1)
    uz = model.dForward(p, (0, 0, 1)).squeeze(-1)

    grad_u = torch.zeros(p.shape[0], 3, device=p.device, dtype=p.dtype)
    grad_u[:, 0] = ux
    grad_u[:, 1] = uy
    grad_u[:, 2] = uz

    # æŠ•å½±åˆ°åˆ‡ç©ºé—´ï¼šgrad_S u = (I - nn^T) grad_u
    grad_u_tan = grad_u - (grad_u * n).sum(dim=1, keepdim=True) * n

    # å•ä½åŒ–å¹¶åŠ ä¸Šè´Ÿå·
    X = -grad_u_tan / (grad_u_tan.norm(dim=1, keepdim=True) + 1e-12)

    return X


def compute_div_X(model, p: torch.Tensor, normal: torch.Tensor, mean_curvature: torch.Tensor,
                  damp=None) -> torch.Tensor:
    """
    div_S X = -(1/||âˆ‡_S u||) Î”_S u
              + ((âˆ‡_S u)^T (Hess_S u) (âˆ‡_S u)) / ||âˆ‡_S u||^3
    å…¶ä¸­ Î”_S u = Î” u - n^T (Hess u) n - 2 Hmean * (âˆ‡u Â· n)
    è¿™é‡Œ Hess u ä¸ºç¯å¢ƒ Hessianï¼Œâˆ‡_S u = (I - n n^T) âˆ‡uï¼ŒHess_S u â‰ˆ P (Hess u) P
    """
    device, dtype = p.device, p.dtype

    # å•ä½æ³•å‘ & å¹³å‡æ›²ç‡
    n = normal / (normal.norm(dim=1, keepdim=True) + 1e-12)  # (N,3)
    Hmean = mean_curvature.view(-1, 1)  # (N,1)

    X = compute_X(model, p, normal)

    Ax = model.features(p).cat(dim=1)
    A = pyrfm.concat_blocks([[Ax, torch.zeros_like(Ax), torch.zeros_like(Ax)],
                             [torch.zeros_like(Ax), Ax, torch.zeros_like(Ax)],
                             [torch.zeros_like(Ax), torch.zeros_like(Ax), Ax]])
    b = torch.cat([X[:, [0]], X[:, [1]], X[:, [2]]], dim=0)

    W_backup = model.W.clone()
    if damp is not None and damp > 0:
        model.compute(A, damp=damp).solve(b)
    else:
        model.compute(A).solve(b)

    dx_X = model.dForward(p, (1, 0, 0))
    dy_X = model.dForward(p, (0, 1, 0))
    dz_X = model.dForward(p, (0, 0, 1))

    H = torch.zeros((p.shape[0], 3, 3))
    # H[:, 0, :] = dx_X
    # H[:, 1, :] = dy_X
    # H[:, 2, :] = dz_X
    H[:, :, 0] = dx_X
    H[:, :, 1] = dy_X
    H[:, :, 2] = dz_X

    # âˆ‡s â‹… v = âˆ‡ â‹… v âˆ’ n^T(âˆ‡v)n
    divX = (dx_X[:, [0]] + dy_X[:, [1]] + dz_X[:, [2]]) - torch.einsum('bi,bij,bj->b', n, H, n).unsqueeze(-1)
    model.W = W_backup

    return divX, None


class ModelPlaneQuad:
    def __call__(self, p):  # å¯é€‰ï¼Œä¸ç”¨ä¹Ÿè¡Œ
        x, y, z = p[:, 0], p[:, 1], p[:, 2]
        return (x ** 2 + y ** 2).unsqueeze(-1)

    def dForward(self, p, order):
        x, y, z = p[:, 0], p[:, 1], p[:, 2]
        ox, oy, oz = order
        if (ox, oy, oz) == (0, 0, 0):
            return (x ** 2 + y ** 2).unsqueeze(-1)
        if (ox, oy, oz) == (1, 0, 0):
            return (2 * x).unsqueeze(-1)
        if (0, 1, 0) == (ox, oy, oz):
            return (2 * y).unsqueeze(-1)
        if (0, 0, 1) == (ox, oy, oz):
            return torch.zeros_like(x).unsqueeze(-1)
        if (2, 0, 0) == (ox, oy, oz):
            return (2.0 + 0.0 * x).unsqueeze(-1)
        if (0, 2, 0) == (ox, oy, oz):
            return (2.0 + 0.0 * y).unsqueeze(-1)
        if (0, 0, 2) == (ox, oy, oz):
            return torch.zeros_like(x).unsqueeze(-1)
        if (1, 1, 0) == (ox, oy, oz) or (1, 0, 1) == (ox, oy, oz) or (0, 1, 1) == (ox, oy, oz):
            return torch.zeros_like(x).unsqueeze(-1)
        raise NotImplementedError(order)


def test_plane(N=5000, radius=1.0):
    # å– z=0 å¹³é¢ä¸Šéšæœºç‚¹ï¼Œæ³•å‘ (0,0,1)ï¼ŒHmean=0
    xy = (torch.rand(N, 2) * 2 - 1) * radius
    p = torch.cat([xy, torch.zeros(N, 1)], dim=1)
    normal = torch.tensor([0.0, 0.0, 1.0]).repeat(N, 1)
    Hmean = torch.zeros(N, 1)

    model = ModelPlaneQuad()
    divX, lap_S_u, g = compute_div_X(model, p, normal, Hmean)

    # è§£æè§£ï¼šdiv_S X = -1/r
    r = xy.norm(dim=1, keepdim=True)
    mask = (r > 1e-6) & (g > 1e-8)
    gt = -1.0 / r
    err = (divX - gt).abs()[mask]

    print("\n[Plane z=0, u=x^2+y^2]")
    print("Expected: div_S X = -1/r (exclude râ‰ˆ0)")
    print(f"mask ratio used: {mask.double().mean().item():.3f}")
    print(f"abs error: mean={err.mean().item():.3e}, median={err.median().item():.3e}, max={err.max().item():.3e}")
    print(f"Î”_S u (should be 4): mean={lap_S_u.mean().item():.6f}, std={lap_S_u.std().item():.6f}")


class PreciseRFMVisualizer3DMC(pyrfm.RFMVisualizer3DMC):
    @torch.no_grad()
    def _compute_field_values_points(self, pts_world):
        """
        å¤ç”¨ä½ åœ¨ ray-marching ç‰ˆæœ¬ä¸­çš„å­—æ®µå–å€¼é€»è¾‘ï¼Œä½†é’ˆå¯¹ä»»æ„ç‚¹é›†åˆã€‚
        è¿”å› numpy (N,) çš„æ ‡é‡æ•°ç»„ï¼ˆå– component_idx åˆ†é‡ï¼›è‹¥ ref å­˜åœ¨ï¼Œåšç»å¯¹å·®ï¼‰ã€‚
        """
        pts_t = torch.tensor(pts_world, device=self.device, dtype=self.dtype)

        pts_t = self._project_to_surface(
            pts_t,
            max_iter=40,  # å¯æŒ‰éœ€è°ƒå¤§
            atol=torch.finfo(self.dtype).eps,
            rtol=torch.finfo(self.dtype).eps,  # ä¸å‡ ä½•å°ºåº¦ç›¸å¯¹
            batch_size=1 << 15  # é¿å… OOM
        )
        if isinstance(self.model, pyrfm.RFMBase):
            if self.ref is not None:
                field_vals = self.model(pts_t)
                ref_vals = self.ref(pts_t)
                print(field_vals.shape, ref_vals.shape)
                print((field_vals - ref_vals).abs().max())
                field_vals = (field_vals - ref_vals).abs().detach().cpu().numpy()[:, self.component_idx]
            else:
                field_vals = self.model(pts_t).detach().cpu().numpy()[:, self.component_idx]
        elif isinstance(self.model, pyrfm.STRFMBase):
            xt = self.model.validate_and_prepare_xt(x=pts_t,
                                                    t=torch.tensor([[self.t]], device=self.device, dtype=self.dtype))
            if self.ref is not None:
                field_vals = self.model.forward(xt=xt)
                ref_vals = self.ref(xt=xt)
                field_vals = (field_vals - ref_vals).abs().detach().cpu().numpy()[:, self.component_idx]
            else:
                field_vals = self.model.forward(xt=xt).detach().cpu().numpy()[:, self.component_idx]
        else:
            raise NotImplementedError("Model type not supported for visualization.")
        return field_vals

    @torch.no_grad()
    def _project_to_surface(
            self,
            pts: torch.Tensor,
            max_iter: int = 15,
            atol: float = None,
            rtol: float = None,
            batch_size: int = 1 << 15,
    ) -> torch.Tensor:
        """
        ç”¨ self.sdf çš„æœ‰ç¬¦å·è·ç¦»ä¸å•ä½æ³•å‘ï¼Œå°†ä»»æ„ 3D ç‚¹æ›´ç²¾ç¡®åœ°æŠ•å½±åˆ° Ï†=0 æ›²é¢ä¸Šã€‚
        åœæ­¢æ¡ä»¶ï¼šmax(|d|) < max(atol, rtol * L)ï¼Œå…¶ä¸­ L ä¸ºå‡ ä½•ç‰¹å¾å°ºåº¦ï¼ˆæ¥è‡ªåŒ…å›´ç›’ç›´å¾„ï¼‰ã€‚
        """
        # 1) è®¾å¤‡/ç²¾åº¦å¯¹é½
        pts = pts.to(device=self.device, dtype=self.dtype)

        # 2) ä¼°è®¡å‡ ä½•å°ºå¯¸ï¼ˆæ¥è‡ªåŒ…å›´ç›’ï¼‰
        try:
            x_min, x_max, y_min, y_max, z_min, z_max = self.get_bounding_box()
            L = float(max(x_max - x_min, y_max - y_min, z_max - z_min))
        except Exception:
            # fallbackï¼šå•ä½å°ºåº¦
            L = 1.0
        if atol is None:
            # ç»å¯¹é˜ˆå€¼éš dtype/å°ºåº¦è‡ªé€‚åº”
            atol = max(torch.finfo(self.dtype).eps * L * 10, 1e-12)

        # 3) åˆ†æ‰¹è¿­ä»£
        N = pts.shape[0]
        out = torch.empty_like(pts)
        for i0 in range(0, N, batch_size):
            i1 = min(N, i0 + batch_size)
            p = pts[i0:i1].clone()

            for _ in range(max_iter):
                # sdf: (B,1); n: (B,3)
                sdf_val, n = self.sdf(p, with_normal=True)
                if sdf_val.ndim == 2 and sdf_val.size(-1) == 1:
                    sdf_val = sdf_val.squeeze(-1)  # (B,)

                # æ­¥é•¿ï¼šd * n
                step = (sdf_val.unsqueeze(-1)) * n
                p = p - step

                # æ”¶æ•›æ£€æŸ¥ï¼ˆç›¸å¯¹+ç»å¯¹ï¼‰
                thresh = max(atol, rtol * L)
                if torch.max(sdf_val.abs()).item() < thresh:
                    break

            out[i0:i1] = p

        return out


class NormalNormRFMVisualizer3DMC(pyrfm.RFMVisualizer3DMC):
    def _compute_field_values_points(self, pts_world):
        """
        å¤ç”¨ä½ åœ¨ ray-marching ç‰ˆæœ¬ä¸­çš„å­—æ®µå–å€¼é€»è¾‘ï¼Œä½†é’ˆå¯¹ä»»æ„ç‚¹é›†åˆã€‚
        è¿”å› numpy (N,) çš„æ ‡é‡æ•°ç»„ï¼ˆå– component_idx åˆ†é‡ï¼›è‹¥ ref å­˜åœ¨ï¼Œåšç»å¯¹å·®ï¼‰ã€‚
        """
        pts_t = torch.tensor(pts_world, device=self.device, dtype=self.dtype)
        if isinstance(self.model, pyrfm.RFMBase):
            if self.ref is not None:
                # field_vals = self.model(pts_t)
                nx = self.model.dForward(pts_t, (1, 0, 0))
                ny = self.model.dForward(pts_t, (0, 1, 0))
                nz = self.model.dForward(pts_t, (0, 0, 1))
                field_vals = torch.sqrt(nx ** 2 + ny ** 2 + nz ** 2)
                ref_vals = self.ref(pts_t)
                field_vals = (field_vals - ref_vals).abs().detach().cpu().numpy()[:, self.component_idx]
            else:
                nx = self.model.dForward(pts_t, (1, 0, 0))
                ny = self.model.dForward(pts_t, (0, 1, 0))
                nz = self.model.dForward(pts_t, (0, 0, 1))
                field_vals = torch.sqrt(nx ** 2 + ny ** 2 + nz ** 2)
                field_vals = field_vals.detach().cpu().numpy()[:, self.component_idx]

        elif isinstance(self.model, pyrfm.STRFMBase):
            xt = self.model.validate_and_prepare_xt(x=pts_t,
                                                    t=torch.tensor([[self.t]], device=self.device, dtype=self.dtype))
            if self.ref is not None:
                field_vals = self.model.forward(xt=xt)
                ref_vals = self.ref(xt=xt)
                field_vals = (field_vals - ref_vals).abs().detach().cpu().numpy()[:, self.component_idx]
            else:
                field_vals = self.model.forward(xt=xt).detach().cpu().numpy()[:, self.component_idx]
        else:
            raise NotImplementedError("Model type not supported for visualization.")
        return field_vals


class MeanCurvatureRFMVisualizer3DMC(pyrfm.RFMVisualizer3DMC):
    def _compute_field_values_points(self, pts_world):
        """
        å¤ç”¨ä½ åœ¨ ray-marching ç‰ˆæœ¬ä¸­çš„å­—æ®µå–å€¼é€»è¾‘ï¼Œä½†é’ˆå¯¹ä»»æ„ç‚¹é›†åˆã€‚
        è¿”å› numpy (N,) çš„æ ‡é‡æ•°ç»„ï¼ˆå– component_idx åˆ†é‡ï¼›è‹¥ ref å­˜åœ¨ï¼Œåšç»å¯¹å·®ï¼‰ã€‚
        """
        pts_t = torch.tensor(pts_world, device=self.device, dtype=self.dtype)
        if isinstance(self.model, pyrfm.RFMBase):
            if self.ref is not None:
                # field_vals = self.model(pts_t)
                field_vals = self.model.dForward(pts_t, (2, 0, 0))
                field_vals += self.model.dForward(pts_t, (0, 2, 0))
                field_vals += self.model.dForward(pts_t, (0, 0, 2))
                field_vals *= 0.5
                ref_vals = self.ref(pts_t)
                field_vals = (field_vals - ref_vals).abs().detach().cpu().numpy()[:, self.component_idx]
            else:
                field_vals = self.model.dForward(pts_t, (2, 0, 0))
                field_vals += self.model.dForward(pts_t, (0, 2, 0))
                field_vals += self.model.dForward(pts_t, (0, 0, 2))
                field_vals *= 0.5
                field_vals = field_vals.detach().cpu().numpy()[:, self.component_idx]

        elif isinstance(self.model, pyrfm.STRFMBase):
            xt = self.model.validate_and_prepare_xt(x=pts_t,
                                                    t=torch.tensor([[self.t]], device=self.device, dtype=self.dtype))
            if self.ref is not None:
                field_vals = self.model.forward(xt=xt)
                ref_vals = self.ref(xt=xt)
                field_vals = (field_vals - ref_vals).abs().detach().cpu().numpy()[:, self.component_idx]
            else:
                field_vals = self.model.forward(xt=xt).detach().cpu().numpy()[:, self.component_idx]
        else:
            raise NotImplementedError("Model type not supported for visualization.")
        return field_vals


def save_isosurface_png_and_ply(
        save_png_path: Union[str, Path],
        save_ply_path: Union[str, Path],
        *,
        model,
        bbox,
        level: float = 0.0,
        grid: Tuple[int, int, int] = (128, 128, 128),
        resolution: Tuple[int, int] = (800, 800),
        view: str = "front",
        ref=None
):
    # viz = pyrfm.RFMVisualizer3DMC(model, t=0.0, resolution=resolution, component_idx=0, view=view, ref=ref)
    viz = PreciseRFMVisualizer3DMC(model, t=0.0, resolution=resolution, component_idx=0, view=view, ref=ref)
    # viz = NormalNormRFMVisualizer3DMC(model, t=0.0, resolution=resolution, component_idx=0, view=view, ref=ref)
    # viz = MeanCurvatureRFMVisualizer3DMC(model, t=0.0, resolution=resolution, component_idx=0, view=view, ref=ref)
    viz.plot(cmap="viridis", level=level, grid=grid)

    save_png_path = Path(save_png_path);
    save_png_path.parent.mkdir(parents=True, exist_ok=True)
    viz.savefig(str(save_png_path))
    viz.show()
    viz.close()

    # save_ply_path = Path(save_ply_path);
    # save_ply_path.parent.mkdir(parents=True, exist_ok=True)
    # viz.save_ply(str(save_ply_path))
    #
    # try:
    #     import matplotlib.pyplot as _plt
    #     _plt.close('all')
    # except Exception:
    #     pass
    print(f"[Viz-3D] Saved PNG: {save_png_path} | PLY: {save_ply_path}")


# ---------------------- 2D æˆªé¢æ¸²æŸ“ï¼ˆä¿å­˜ï¼‰ ----------------------
def save_model_slice_png(
        save_path: Union[str, Path],
        model,
        bbox,
        *,
        axis: str = "y",
        value: float = 0.0,
        res: int = 256,
        level: float = 0.0,
        cmap: str = "RdBu_r",
        vmin: float | None = None,
        vmax: float | None = None,
        symmetric: bool = True,
        device: Union[torch.device, str, None] = None,
):
    assert axis in ("x", "y", "z")
    if device is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    xr, yr, zr = (bbox[0], bbox[1]), (bbox[2], bbox[3]), (bbox[4], bbox[5])
    if axis == "x":
        value = float(np.clip(value, *xr))
    elif axis == "y":
        value = float(np.clip(value, *yr))
    else:
        value = float(np.clip(value, *zr))

    axis2idx = {"x": 0, "y": 1, "z": 2}
    fixed = axis2idx[axis]
    free = [i for i in range(3) if i != fixed]
    ranges = [xr, yr, zr]

    u = torch.linspace(ranges[free[0]][0], ranges[free[0]][1], res, device=device)
    v = torch.linspace(ranges[free[1]][0], ranges[free[1]][1], res, device=device)
    U, V = torch.meshgrid(u, v, indexing="ij")

    P = torch.zeros((res * res, 3), device=device)
    P[:, free[0]] = U.reshape(-1)
    P[:, free[1]] = V.reshape(-1)
    P[:, fixed] = value

    with torch.no_grad():
        out = model(P)
        if out.ndim == 2 and out.size(-1) == 1:
            out = out.squeeze(-1)
        Z = out.reshape(res, res).detach().cpu().numpy()

    data_min, data_max = Z.min(), Z.max()
    if symmetric:
        bound = max(abs(data_min), abs(data_max))
        data_vmin, data_vmax = -bound, bound
    else:
        data_vmin = data_min if vmin is None else vmin
        data_vmax = data_max if vmax is None else vmax

    if not (data_vmin < level < data_vmax):
        pad = 1e-6 * max(1.0, abs(level))
        data_vmin = min(data_vmin, level - pad)
        data_vmax = max(data_vmax, level + pad)

    norm = TwoSlopeNorm(vmin=data_vmin, vcenter=level, vmax=data_vmax)
    extent = (ranges[free[0]][0], ranges[free[0]][1], ranges[free[1]][0], ranges[free[1]][1])

    plt.figure(figsize=(6, 5))
    im = plt.imshow(Z.T, origin="lower", extent=extent, aspect="equal", cmap=cmap, norm=norm)
    cbar = plt.colorbar(im, label="model value")
    ticks = np.linspace(data_vmin, data_vmax, 7)
    cbar.set_ticks(ticks);
    cbar.set_ticklabels([f"{t:.2f}" for t in ticks])

    cs = plt.contour(np.linspace(*ranges[free[0]], res),
                     np.linspace(*ranges[free[1]], res),
                     Z.T, levels=[level], colors="k", linewidths=2.0)
    plt.clabel(cs, fmt=f"{level:g}")

    labels = ["x", "y", "z"]
    plt.xlabel(labels[free[0]]);
    plt.ylabel(labels[free[1]])
    plt.title(f"{labels[fixed]} = {value:.3f} slice (white at {level:g})")
    plt.tight_layout()
    save_path = Path(save_path)
    save_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(save_path, dpi=200)
    plt.close()
    print(f"[Viz-2D] Saved: {save_path}")


def restore_plain_state_dict(state_dict, eps=1e-12):
    """
    å°†å¸¦æœ‰ `parametrizations.weight.original*` çš„æƒé‡è¿˜åŸä¸ºæ™®é€š `...weight`ã€‚
    å‡è®¾é‡‡ç”¨çš„æ˜¯ PyTorch çš„ weight_normï¼Œé»˜è®¤ dim=0ï¼ˆä¸å®˜æ–¹é»˜è®¤ä¸€è‡´ï¼‰ã€‚
    å¯¹äº Linear/Conv/Embedding éƒ½å¯ç”¨ï¼šå¯¹ v åœ¨ dims = (1..N-1) ä¸Šåš L2 èŒƒæ•°ã€‚
    """
    # æ”¶é›†æ‰€æœ‰å±‚çš„ (g, v) æŒ‡é’ˆ
    buckets = defaultdict(dict)
    pat = re.compile(r"^(.*)\.parametrizations\.weight\.original([01])$")
    for k in state_dict.keys():
        m = pat.match(k)
        if m:
            prefix, idx = m.group(1), m.group(2)
            buckets[prefix][idx] = k  # è®°å½• original0 / original1 çš„å®Œæ•´ key

    new_sd = {}

    # å…ˆå¤åˆ¶åŸæ¥å°±å·²æ˜¯â€œæ™®é€šâ€çš„å‚æ•°ï¼ˆä¾‹å¦‚ final_layer.weight/biasã€ä»»æ„ biasï¼‰
    for k, v in state_dict.items():
        if ".parametrizations.weight.original" in k:
            continue  # ç¨åè¿˜åŸåä¼šä»¥ ...weight çš„æ–° key æ”¾è¿›å»
        new_sd[k] = v

    # å¯¹æ¯ä¸ªéœ€è¦è¿˜åŸçš„æƒé‡æ‰§è¡Œ weight_norm é€†å˜æ¢
    for prefix, pair in buckets.items():
        if "0" not in pair or "1" not in pair:
            raise ValueError(f"{prefix} ç¼ºå°‘ original0/1ï¼Œæ— æ³•è¿˜åŸã€‚")

        g = state_dict[pair["0"]].clone()
        v = state_dict[pair["1"]].clone()

        # è®¡ç®— ||v||ï¼Œå¯¹é™¤ç¬¬ 0 ç»´ä»¥å¤–çš„å…¨éƒ¨ç»´åº¦åšèŒƒæ•°ï¼ˆç­‰ä»·äº weight_norm çš„é»˜è®¤ dim=0ï¼‰
        if v.dim() == 1:
            # ä¾‹å¦‚æŸäº›ç‰¹æ®Šæƒ…å†µï¼šæŠŠ 1D å½“ä½œ (out,) â€”â€” è¿™æ—¶èŒƒæ•°å°±æ˜¯ç»å¯¹å€¼
            v_norm = v.abs() + eps
            scale = g / v_norm
            w = v * scale
        else:
            reduce_dims = tuple(range(1, v.dim()))
            v_norm = v.norm(dim=reduce_dims, keepdim=True) + eps
            # g å½¢çŠ¶é€šå¸¸æ˜¯ (out,)ï¼›éœ€è¦ reshape æˆ (out, 1, 1, ...) æ‰èƒ½å¹¿æ’­
            shape = [g.shape[0]] + [1] * (v.dim() - 1)
            scale = g.view(*shape) / v_norm
            w = v * scale

        # æŠŠè¿˜åŸåçš„æƒé‡å†™å›ä¸º `<prefix>.weight`
        new_sd[f"{prefix}.weight"] = w

    return new_sd


class BoundingBox:
    def __init__(self, x_min, x_max, y_min, y_max, z_min, z_max):
        self.x_min = float(x_min);
        self.x_max = float(x_max)
        self.y_min = float(y_min);
        self.y_max = float(y_max)
        self.z_min = float(z_min);
        self.z_max = float(z_max)

    def get_bounding_box(self):
        return (self.x_min, self.x_max, self.y_min, self.y_max, self.z_min, self.z_max)

    def sample(self, num_samples):
        n = int(num_samples ** (1 / 3)) + 1
        x = torch.linspace(self.x_min, self.x_max, n)
        y = torch.linspace(self.y_min, self.y_max, n)
        z = torch.linspace(self.z_min, self.z_max, n)
        xx, yy, zz = torch.meshgrid(x, y, z, indexing="ij")
        grid_points = torch.stack([xx, yy, zz], dim=-1).view(-1, 3)
        return grid_points

    def expand(self, margin=None, ratio=None):
        if margin is None and ratio is None:
            raise ValueError("å¿…é¡»æŒ‡å®š margin æˆ– ratio")
        if margin is not None:
            self.x_min -= margin;
            self.x_max += margin
            self.y_min -= margin;
            self.y_max += margin
            self.z_min -= margin;
            self.z_max += margin
        if ratio is not None:
            cx = (self.x_min + self.x_max) / 2
            cy = (self.y_min + self.y_max) / 2
            cz = (self.z_min + self.z_max) / 2
            hx = (self.x_max - self.x_min) / 2 * ratio
            hy = (self.y_max - self.y_min) / 2 * ratio
            hz = (self.z_max - self.z_min) / 2 * ratio
            self.x_min, self.x_max = cx - hx, cx + hx
            self.y_min, self.y_max = cy - hy, cy + hy
            self.z_min, self.z_max = cz - hz, cz + hz
        return self


def func_Dirac(x, x0, sigma):
    """
    é«˜æ–¯å‡½æ•°æé™å½¢å¼çš„ç‹„æ‹‰å…‹ Î´ å‡½æ•°è¿‘ä¼¼
    Î´(x âˆ’ xâ‚€) = lim (Ïƒ â†’ 0) 1/(Ïƒâˆš(2Ï€)) exp(âˆ’(x âˆ’ xâ‚€)Â²/(2ÏƒÂ²))
    :param x: è¾“å…¥å¼ é‡
    :param x0: ç‚¹æºä½ç½®
    :param sigma: æ ‡å‡†å·®ï¼Œæ§åˆ¶å®½åº¦ï¼ˆæ•°å€¼ä¸Šå–ä¸€ä¸ªå°çš„æ­£æ•°ï¼‰
    :return: è¿‘ä¼¼çš„ Î´(x - x0)
    """
    coeff = 1.0 / (sigma * torch.sqrt(torch.tensor(2.0 * torch.pi)))  # å½’ä¸€åŒ–ç³»æ•°
    r = (x - x0).norm(dim=1, p=2, keepdim=True)
    gauss = torch.exp(-0.5 * (r / sigma) ** 2) * coeff  # é«˜æ–¯å‡½æ•°
    return gauss


if __name__ == '__main__':
    torch.set_default_device('cuda') if torch.cuda.is_available() else torch.set_default_device('cpu')
    device = torch.tensor(0.0).device
    dtype = torch.tensor(0.0).dtype

    # test_plane(5000, radius=1.0)

    for shape in ["ellipsoid", "torus"]:
        pth_path = '../../data/{}_m.pth'.format(shape)
        pt_path = "../../sec3/sec3_2/checkpoints/{}_in/tanh-tanh/sdf_best.pt".format(shape)
        ckpt = torch.load(pt_path, map_location=device)
        plain_state_dict = restore_plain_state_dict(ckpt["model_state"])
        domain = pyrfm.Square3D(center=(0.0, 0.0, 0.0), radius=(1, 1, 1))
        model = pyrfm.RFMBase(dim=3, n_hidden=512, domain=domain, n_subdomains=1, rf=pyrfm.RFTanH2)
        model.submodels[0].inner.weights = plain_state_dict["input_layer.0.weight"].t()
        model.submodels[0].inner.biases = plain_state_dict["input_layer.0.bias"]
        model.submodels[0].weights = plain_state_dict["hidden_layer.0.weight"].t()
        model.submodels[0].biases = plain_state_dict["hidden_layer.0.bias"]
        # model.W = plain_state_dict["final_layer.weight"].t()

        x_in, normal, mean_curvature = torch.load(pth_path)

        mins = x_in.min(dim=0).values
        maxs = x_in.max(dim=0).values
        bbox = BoundingBox(mins[0].item(), maxs[0].item(),
                           mins[1].item(), maxs[1].item(),
                           mins[2].item(), maxs[2].item()).expand(
            ratio=1.5 if shape in ["bunny", "cheese"] else 1.1 if shape == "genus2" else 1.2)
        ## adjust ratio to look better

        # -----------------------------------
        # ğŸ”§ è®¡æ—¶å¼€å§‹ï¼šç»„è£…çŸ©é˜µ
        t0 = time.time()
        # -----------------------------------

        # find 10 points x_in.x is largest

        n_points = x_in.shape[0]
        k = 1
        idx_max_y = torch.argmin(x_in[:, 1])  # å•ä¸ªç´¢å¼•
        p_max_y = x_in[idx_max_y]  # å¯¹åº”çš„ç‚¹ (1,3)
        dist = torch.norm(x_in - p_max_y, dim=1)
        indices = torch.topk(dist, k=k, largest=False).indices

        # on-set
        x_on = x_in[indices]
        x_on = x_on.repeat(10, 1)
        A_on = model.features(x_on).cat(dim=1)

        # indices = torch.topk(x_in[:, 1], k=1, largest=True).indices
        # x_boundary = x_in[indices]
        # x_boundary = x_boundary.repeat(1000, 1)
        # A_boundary = model.features(x_boundary).cat(dim=1)

        # # æ„é€  maskï¼Œå»æ‰è¿™äº› indices
        mask = torch.ones(n_points, dtype=torch.bool, device=x_in.device)
        mask[indices] = False
        x_in = x_in.clone()[mask]
        normal = normal[mask]
        mean_curvature = mean_curvature[mask]

        A_in = model.features(x_in).cat(dim=1)
        A_xx = model.features_second_derivative(x_in, axis1=0, axis2=0).cat(dim=1)
        A_yy = model.features_second_derivative(x_in, axis1=1, axis2=1).cat(dim=1)
        A_zz = model.features_second_derivative(x_in, axis1=2, axis2=2).cat(dim=1)
        A_xy = model.features_second_derivative(x_in, axis1=0, axis2=1).cat(dim=1)
        A_xz = model.features_second_derivative(x_in, axis1=0, axis2=2).cat(dim=1)
        A_yz = model.features_second_derivative(x_in, axis1=1, axis2=2).cat(dim=1)

        A_lap = A_xx + A_yy + A_zz

        # æ‰‹åŠ¨å±•å¼€ einsum('ni,nijk,nj->nk') ç­‰ä»·äºï¼š
        A_nHn = (
                normal[:, 0:1] * (A_xx * normal[:, 0:1] + A_xy * normal[:, 1:2] + A_xz * normal[:, 2:3]) +
                normal[:, 1:2] * (A_xy * normal[:, 0:1] + A_yy * normal[:, 1:2] + A_yz * normal[:, 2:3]) +
                normal[:, 2:3] * (A_xz * normal[:, 0:1] + A_yz * normal[:, 1:2] + A_zz * normal[:, 2:3])
        )

        # å¯é€‰é‡Šæ”¾å†…å­˜
        del A_xx, A_yy, A_zz, A_xy, A_xz, A_yz
        torch.cuda.empty_cache()

        A_in_x = model.features_derivative(x_in, axis=0).cat(dim=1)
        A_in_y = model.features_derivative(x_in, axis=1).cat(dim=1)
        A_in_z = model.features_derivative(x_in, axis=2).cat(dim=1)

        A_grad = torch.stack([A_in_x, A_in_y, A_in_z], dim=1)
        # print(A_grad.shape)  # (N, 3, M)
        A_partial_n = (
                normal[:, 0:1] * A_in_x +
                normal[:, 1:2] * A_in_y +
                normal[:, 2:3] * A_in_z
        )

        # âˆ‡_S u = (I - n n^T) âˆ‡u  (N, 3, M)
        A_surface_grad = A_grad - normal.unsqueeze(-1) * A_partial_n.unsqueeze(1)

        del A_in_x, A_in_y, A_in_z
        torch.cuda.empty_cache()

        A_lap_beltrami = A_lap - 2 * mean_curvature * A_partial_n - A_nHn

        del A_lap, A_partial_n, A_nHn, A_grad
        torch.cuda.empty_cache()

        # -----------------------------------
        # ğŸ”§ è®¡æ—¶ç»“æŸï¼šç»„è£…çŸ©é˜µ
        # t1 = time.time()
        # print(f'[Timer] Matrix assembly time: {t1 - t0:.2f} seconds')
        # -----------------------------------

        # -----------------------------------
        # ğŸ§® è®¡æ—¶å¼€å§‹ï¼šæ±‚è§£ç³»ç»Ÿ
        # t2 = time.time()
        # -----------------------------------

        # A1 = pyrfm.concat_blocks([[A_in], [A_on]])
        # b_in = torch.zeros(x_in.shape[0], 1)
        # b_on = torch.ones(x_on.shape[0], 1)
        # b = pyrfm.concat_blocks([[b_in], [b_on]])
        # model.compute(A1, damp=1e-2).solve(b)
        # #
        # t_small = 1e-6
        # A2_in = pyrfm.concat_blocks([[A_in - t_small * A_lap_beltrami]])
        # A2 = pyrfm.concat_blocks([[A2_in], [A_on]])
        # b_in = model(x_in)
        # b_on = model(x_on)
        # b_in = func_Dirac(x_in, p_max_y, sigma=0.05)
        # print(b_in)
        # b_on = func_Dirac(x_on, p_max_y, sigma=0.05)
        # b = pyrfm.concat_blocks([[b_in], [b_on]])
        # model.compute(A2, damp=1e-8).solve(b)

        # model.compute(A2_in, damp=1e-3).solve(b_in)

        t_small = 1e-6
        A1_in = pyrfm.concat_blocks([[A_in - t_small * A_lap_beltrami]])
        b1_in = torch.zeros(x_in.shape[0], 1)
        A = pyrfm.concat_blocks([[A1_in], [A_on]])
        b_on = torch.ones(x_on.shape[0], 1)
        b = pyrfm.concat_blocks([[b1_in], [b_on]])
        model.compute(A, damp=1e-8).solve(b)

        # X = compute_X(model, x_in, normal)
        #
        # A3_in = torch.cat([A_surface_grad[:, 0, :], A_surface_grad[:, 1, :], A_surface_grad[:, 2, :]], dim=0)
        # b3_in = torch.cat([X[:, [0]], X[:, [1]], X[:, [2]]], dim=0)
        # A3 = pyrfm.concat_blocks([[A3_in], [A_on]])
        # b_on = torch.zeros(x_on.shape[0], 1)
        # b3 = pyrfm.concat_blocks([[b3_in], [b_on]])
        # model.compute(A3, damp=1e-8).solve(b3)

        # A3 = pyrfm.concat_blocks([[A_in, torch.zeros_like(A_in), torch.zeros_like(A_in)],
        #                           [torch.zeros_like(A_in), A_in, torch.zeros_like(A_in)],
        #                           [torch.zeros_like(A_in), torch.zeros_like(A_in), A_in]])
        # b_in = compute_X(model, x_in, normal)

        # x_all = torch.cat([x_in, x_on], dim=0)
        # A_all = model.features(x_all).cat(dim=1)
        # b_in = compute_div_X_autograd(model, x_in, normal, mean_curvature)
        # b_all = torch.cat([b_in, torch.zeros(x_on.shape[0], 1)], dim=0)
        # model.compute(A_all).solve(b_all)

        #
        # b_in = compute_div_X(model, x_in, normal, mean_curvature, 1e-8)[0]
        # b_on = torch.zeros(x_on.shape[0], 1)
        # b = pyrfm.concat_blocks([[b_in], [b_on]])
        #
        # A = pyrfm.concat_blocks([[A_lap_beltrami], [A_on]])
        # model.compute(A, damp=1e-8).solve(b)

        # del A
        # torch.cuda.empty_cache()

        # -----------------------------------
        # ğŸ§® è®¡æ—¶ç»“æŸ
        t3 = time.time()
        # print(f'[Timer] Linear solve time: {t3 - t2:.2f} seconds')
        # -----------------------------------

        print(f'[Timer] Total time: {t3 - t0:.2f} seconds')

        u_pred = model(x_in)
        print(u_pred)


        # print(u_pred / compute_div_X(model, x_in, normal, mean_curvature)[0].norm(dim=1, keepdim=True))

        # u_exact = func_u(x_in)
        #
        # error = torch.norm(u_pred - u_exact) / torch.norm(u_exact)
        # print(f'Error: {error.item():.4e}')

        # model.W = plain_state_dict["final_layer.weight"].t()

        class NearShapeForViz(pyrfm.ImplicitSurfaceBase):
            def __init__(self, model, domain):
                super().__init__()
                self.model = model  # è¿™é‡Œä¸€å®šè¦æŒ‚ä¸Šæ”¯æŒ dForward çš„ RFM æ¨¡å‹
                self._domain = domain

            def get_bounding_box(self):
                return bbox.get_bounding_box()

            def shape_func(self, p: torch.Tensor) -> torch.Tensor:
                # è¿”å›æ¨¡å‹é¢„æµ‹çš„ SDF
                return self.model(p).squeeze(-1)


        shape_model = pyrfm.RFMBase(dim=3, n_hidden=512, domain=domain, n_subdomains=1, rf=pyrfm.RFTanH2)
        shape_model.submodels[0].inner.weights = plain_state_dict["input_layer.0.weight"].t()
        shape_model.submodels[0].inner.biases = plain_state_dict["input_layer.0.bias"]
        shape_model.submodels[0].weights = plain_state_dict["hidden_layer.0.weight"].t()
        shape_model.submodels[0].biases = plain_state_dict["hidden_layer.0.bias"]
        shape_model.W = plain_state_dict["final_layer.weight"].t()

        near_shape = NearShapeForViz(shape_model, domain)

        model.domain = near_shape

        save_isosurface_png_and_ply("../figures/{}_geo.png".format(shape), "/dev/null",
                                    model=model, bbox=domain, level=0.0, grid=(128, 128, 128),
                                    resolution=(800, 800), view="iso")
        #
        # save_isosurface_png_and_ply("../figures/{}_iso_err.png".format(shape), "/dev/null",
        #                             model=model, bbox=domain, level=0.0, grid=(256, 256, 256),
        #                             resolution=(800, 800), view="iso", ref=func_u)
